# 🏠 House Price Prediction: Regression & Classification Study Note

## 📌 1. 프로젝트 개요 & 목표
* **목표**: 주택 특성 데이터(`bedrooms`, `sqft`, `floors` 등)를 활용하여 집값(`price`)을 예측하는 최적의 회귀 모델 구축.
* **핵심 전략**: 데이터의 특성과 모델의 성격에 맞춰 **'Two-Track' (선형 vs 트리)** 전략으로 데이터를 이원화하여 관리.
* **학습 포인트**: EDA를 통한 데이터 분포 파악, 이상치 제거, 그리고 하이퍼파라미터 튜닝을 통한 성능 극대화.

---

## 🛠 2. 사용 라이브러리 및 도구 (Tools)

### 2-1. 데이터 처리 및 기초 연산
* **numpy (np), pandas (pd)**: 데이터 분석의 기본. 행렬 연산과 데이터프레임 조작.
* **scipy (stats)**: `probplot`을 활용해 데이터가 정규분포를 따르는지 통계적으로 확인 (**QQ-Plot**).

### 2-2. 데이터 시각화 (Visualization)
* **matplotlib (plt), seaborn (sns)**: 기본적인 데이터 시각화.
* **gridspec**: 복잡한 레이아웃(예: 히스토그램, QQ-plot, Box-plot을 한 화면에 배치)을 구현할 때 사용.
* **mplot3d**: 변수 3개(가격, 연식, 상태)의 관계를 입체적으로 산점도(Scatter)로 확인.

### 2-3. 머신러닝 (Machine Learning)
* **sklearn (Scikit-learn)**:
    * **Preprocessing**: `LabelEncoder`(범주형→수치형), `StandardScaler`(정규화).
    * **Model Selection**: `GridSearchCV` (모든 경우의 수를 대입해 최적 파라미터 탐색), `train_test_split`.
* **Boosting Models**:
    * **xgboost (xgb)**: 강력한 성능, 다양한 규제 옵션.
    * **lightgbm (lgb)**: 빠른 속도와 대용량 데이터 처리에 강점 (최종 우승 모델 🏆).

### 2-4. 하이퍼파라미터 최적화
* **hyperopt**: 단순 랜덤/그리드 서치가 아닌, **베이지안 최적화**를 통해 "더 가능성 높은 파라미터"를 스마트하게 탐색.

---

## 📊 3. 데이터셋 분석 (Columns & Preprocessing)

### 3-1. 주요 변수 설명 및 처리 이슈
| 변수명 | 설명 | 데이터 특징 및 처리 내용 |
| :--- | :--- | :--- |
| **price** | **Target**. 집값 | `0`원인 데이터(노이즈) 존재 → 필터링 필수. |
| **bedrooms** | 침실 개수 | 4.5개 초과 데이터는 이상치로 간주하여 제거. |
| **floors** | 층수 | 1.5층, 2.5층 등 소수점 존재. (⚠️ `int` 변환 시 정보 손실 주의) |
| **sqft_living** | 주거 공간 면적 | 집값과 가장 높은 상관관계를 가짐. |
| **sqft_basement** | 지하실 면적 | `0`(없음)인 값이 많음 → 유무(`0`/`1`) 파생 변수 생성 고려. |
| **yr_built** | 건축 연도 | 오래된 집과 신축의 가격 차이 분석. |
| **city** | 도시 이름 | `LabelEncoder`를 통해 숫자(`0`, `1`, `2`...)로 변환. |

---

## 🔄 4. 분석 파이프라인 (Analysis Flow)

### Step 1. 데이터 로드 및 시각화 (EDA)
* 데이터를 불러온 후 **3종 세트 시각화(Histogram, QQ-Plot, Box-Plot)** 수행.
* **목적**: 데이터의 치우침(Skewness)을 확인하고 **로그 변환(Log Transform)** 여부를 결정하기 위함.

### Step 2. 전처리 (Preprocessing) - "노이즈 제거"
* `price=0`인 데이터 삭제.
* 비현실적인 고가 주택 및 방 개수가 너무 많은 데이터 삭제 (이상치 제어).

### Step 3. 모델링 전략 수립 (The "Two-Track" Strategy) ⭐
이 프로젝트의 **핵심 차별점**. 모델의 특성에 따라 학습 데이터를 두 가지 버전으로 준비함.

1.  **Track A: `train0b` (Unscaled)**
    * **용도**: XGBoost, LightGBM, Random Forest (트리 기반 모델).
    * **이유**: 트리 모델은 "100보다 큰가/작은가"의 규칙(Rule)이 중요하므로, **원본 값의 크기**를 유지하는 것이 해석에 유리함.
2.  **Track B: `train0` (Scaled)**
    * **용도**: Linear Regression, SVM (선형/거리 기반 모델).
    * **이유**: 숫자 단위가 다르면(예: 방 개수 vs 면적) 모델이 왜곡되므로, `StandardScaler`로 단위를 통일함.

### Step 4. 모델 튜닝 및 학습
* **자동 채점 함수 (`acc_boosting_model`)**: 반복적인 학습/평가 과정을 함수화하여 효율성 증대.
* **병렬 처리**: `n_jobs=-1` 옵션을 사용하여 CPU 코어를 모두 활용, 학습 속도 가속.
* **LightGBM 전략**: 낮은 학습률(`0.01`)과 많은 반복 횟수(`10,000`)를 설정하여 정교하게 학습(Squeezing).

### Step 5. 최종 평가 (Evaluation)
* **과적합 확인**: Train 점수와 Test 점수를 그래프로 그려 격차(Gap) 확인.
* **최종 선정**: R2 Score, RMSE, Relative Error를 종합적으로 비교하여 **LightGBM**을 최종 모델로 선정.

---

## 💡 5. 배운 점 & 개선 아이디어 (Retrospective)

### ✅ 핵심 배운 점 (Key Takeaways)
1.  **분포 확인의 중요성**: 무작정 모델을 돌리기 전에 QQ-Plot 등으로