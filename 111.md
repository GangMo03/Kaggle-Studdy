# 🏠 주택 가격 예측 프로젝트 (House Price Prediction)

## 📌 프로젝트 개요
* **목표**: 주택 특성 데이터(`bedrooms`, `sqft`, `floors` 등)를 활용하여 집값(`price`)을 예측하는 최적의 회귀 모델 구축
* **핵심 전략**: 데이터 특성에 맞춰 **선형 모델(Linear)**과 **트리 모델(Tree/Boosting)**을 이원화하여 관리하는 **'Two-Track' 전략** 사용
* **사용 모델**: XGBoost, LightGBM, Random Forest, Linear Regression 등

---

## 🛠 사용 라이브러리 (Libraries)

### 1. 데이터 처리 및 연산
* **pandas (pd), numpy (np)**: 데이터프레임 조작 및 행렬 연산
* **scipy (stats)**: 정규성 검정 (QQ-Plot 등)

### 2. 시각화
* **matplotlib (plt), seaborn (sns)**: 데이터 분포 및 상관관계 시각화
* **mplot3d**: 3차원 산점도 시각화

### 3. 머신러닝 & 딥러닝
* **sklearn**: 전처리(`StandardScaler`, `LabelEncoder`), 모델링(`RandomForest`, `LinearReg`), 평가(`RMSE`, `R2`)
* **xgboost (xgb), lightgbm (lgb)**: 고성능 부스팅 모델
* **hyperopt**: 베이지안 최적화 기반 하이퍼파라미터 튜닝

---

## 📊 데이터셋 설명 (Columns)

| 변수명 | 설명 | 비고 |
| :--- | :--- | :--- |
| **price** | **타겟(Target)**. 집의 판매 가격 | 0원인 이상치 존재 (전처리 필수) |
| **bedrooms** | 침실 개수 | 4.5개 초과 데이터는 제거함 |
| **floors** | 층수 | 1.5층, 2.5층 등 소수점 존재 |
| **sqft_living** | 주거 공간 면적 | 집값과 상관관계가 가장 높은 변수 |
| **sqft_basement** | 지하실 면적 | 0(없음)인 경우가 많음 |
| **yr_built** | 건축 연도 | 노후도 파악 가능 |
| **city** | 도시 이름 | Label Encoding 처리 |
| **date** | 판매 날짜 | (본 분석에서는 사용되지 않음) |

---

## 🔄 분석 파이프라인 (Pipeline)

1.  **데이터 로드 & EDA**: 데이터의 분포(Distribution), 이상치(Outlier), 상관관계(Correlation) 확인
2.  **전처리 (Preprocessing)**: 노이즈 제거, 인코딩, 스케일링
3.  **피처 중요도 (Feature Importance)**: 4가지 모델을 통해 핵심 변수 선별
4.  **모델링 준비 (Two-Track)**: 원본 데이터(Tree용) vs 스케일링 데이터(Linear용) 분리
5.  **모델 튜닝 & 경쟁**: GridSearch/Hyperopt를 통한 최적화 및 모델 간 성능 비교
6.  **최종 예측**: 우승 모델(LightGBM)로 Test 데이터 예측

---

## 📝 단계별 상세 분석

### 1️⃣ EDA (탐색적 데이터 분석)
* **3종 세트 시각화**: `Histogram`(치우침), `QQ-Plot`(정규성), `Box Plot`(이상치)을 한 번에 확인.
* **로그 변환 (Log Transform)**: 타겟(`price`)의 분포가 왼쪽으로 쏠려 있어 로그를 취해 정규분포에 가깝게 만듦.

### 2️⃣ 전처리 (Preprocessing)
* **이상치 제거**: `price=0`인 데이터(49개)와 비현실적인 고가 주택 제거.
* **인코딩 (Encoding)**: 문자열 변수(`city` 등)를 `LabelEncoder`를 통해 숫자로 변환.

### 3️⃣ 모델링 전략 (Two-Track Strategy) ⭐
이 프로젝트의 핵심은 모델 특성에 따라 데이터를 다르게 준비한 점입니다.

1.  **Track A: 부스팅 모델용 (`train0b`)**
    * **대상**: XGBoost, LightGBM, Random Forest
    * **특징**: **원본 데이터 유지**. 트리 모델은 숫자의 크기보다 대소 관계(Rule)가 중요하므로 스케일링이 필요 없음.
2.  **Track B: 선형 모델용 (`train0`)**
    * **대상**: Linear Regression, SVM
    * **특징**: **StandardScaler 적용**. 모든 변수를 평균 0, 분산 1로 맞춰 변수 간 단위를 통일함.

### 4️⃣ 모델 튜닝 및 평가
* **자동 채점 함수**: `acc_boosting_model` 함수를 만들어 반복적인 평가(R2, RMSE) 자동화.
* **Tuning**:
    * **XGBoost**: `GridSearchCV`로 최적 조합 탐색.
    * **LightGBM**: 낮은 학습률(`learning_rate=0.01`)과 많은 반복(`num_boost_round=10000`)으로 정교하게 학습.
* **과적합 확인**: Train 점수와 Test 점수를 그래프로 비교하여 일반화 성능 확인.

---

## 💡 Code Review & Feedback (배운 점 & 개선점)

### ✅ 잘한 점 (Good)
1.  **엄격한 데이터 필터링**: `price=0`인 데이터를 찾아내 제거한 점은 모델 성능 향상에 결정적임.
2.  **모델별 맞춤 데이터셋**: 선형 모델과 트리 모델의 특성을 이해하고 데이터를 분리한 점이 훌륭함.
3.  **다각도 시각화**: 단순히 산점도만 보는 게 아니라 3D 그래프, QQ-Plot 등을 활용해 깊이 있게 분석함.

### ⚠️ 유의할 점 및 개선 제안 (Fix It)
1.  **1.5층 데이터 왜곡**:
    ```python
    # train0['floors'] = (train0['floors']).astype(int)  <-- 삭제 권장!
    ```
    * 1.5층이나 2.5층을 강제로 `int`로 바꾸면 정보 손실이 발생함. 실제 데이터 그대로 `float`를 유지하는 것이 좋음.
2.  **날짜 데이터 활용**:
    * `date` 컬럼을 삭제하기보다, **'연도'**와 **'월'**을 추출했다면 집값의 상승 추세나 계절성을 반영할 수 있었을 것임.
3.  **지하실 변수 세분화**:
    * `sqft_basement`가 0인 경우가 많으므로, **'지하실 유무(0/1)'** 변수를 추가했다면 모델이 더 쉽게 학습했을 것임.

---

## 📚 핵심 개념 Q&A

**Q. 왜 데이터 분포(Distribution)를 확인하나요?**
> A. 데이터가 한쪽으로 쏠려있으면(Skewed) 모델이 학습하기 어렵습니다. 이를 확인하고 **로그 변환** 등을 적용하기 위함입니다.

**Q. RMSE가 무엇인가요?**
> A. **Root Mean Squared Error**. 예측값과 실제값의 차이(오차)를 제곱해 평균 낸 뒤 루트를 씌운 값입니다. **작을수록 좋은 모델**입니다.

**Q. 스케일링(Scaling)은 왜 하나요?**
> A. '방 개수(1~5)'와 '면적(500~4000)'처럼 단위가 다르면, 선형 모델은 **숫자가 큰 변수가 더 중요하다고 착각**할 수 있어 단위를 맞춰주는 것입니다.