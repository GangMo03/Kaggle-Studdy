# 🩺 Fetal Health Classification: 머신러닝 환경 및 라이브러리 세팅

이 단계는 태아의 심박동수(CTG) 등 의료 데이터를 분석하고, 정상(Normal) / 의심(Suspect) / 병적(Pathologic) 상태를 분류할 인공지능 모델들을 준비하는 필수 과정입니다.

## 1. 데이터 핸들링 및 시각화 (Data & Visualization)
## 2. 데이터 전처리 및 파이프라인 (Preprocessing & Pipeline)
* **`Pipeline`**: 전처리와 모델 학습 과정을 하나의 파이프처럼 부드럽게 연결하여 코드를 간결하게 만듭니다.
## 3. 머신러닝 분류 모델 (Classification Models)
태아의 건강 상태를 3가지 다중 클래스로 분류하기 위해, 각기 다른 장점을 가진 알고리즘을 활용합니다.
* **`SVC` / `LinearSVC`**: 데이터 사이의 경계선(Margin)을 가장 넓게 그려서 분류하는 서포트 벡터 머신입니다.
## 4. 모델 튜닝 및 교차 검증 (Tuning & Validation)
* **`GridSearchCV`**: 모델의 세부 설정값(Hyperparameter)을 자동으로 바꿔가며 최적의 성능 조합을 찾아냅니다.
* **`cross_val_score`**: 데이터를 여러 조각으로 나누어 번갈아 가며 시험을 치르게 하여, 모델의 신뢰도를 높입니다.
## 5. 핵심 평가 지표 (Evaluation Metrics)
의료 데이터 분석에서는 단순히 '정확도'만 보지 않고, 다양한 각도에서 모델을 채점하는 것이 핵심입니다.
* **`confusion_matrix`**: 정답과 오답을 표 형태로 보여주어, 모델이 어떤 상태를 헷갈려하는지 파악합니다. 
* **`accuracy_score`**: 전체 중 맞춘 비율입니다. (단, 클래스 불균형이 있을 땐 주의가 필요합니다.)
* **`precision_score` / `recall_score`**: 의료 데이터에서는 **재현율(Recall)**이 특히 중요합니다. "실제 병적(Pathologic) 상태인 태아를 모델이 얼마나 놓치지 않고 찾아냈는가?"를 평가합니다.
## 6. 재현성 확보 (Reproducibility)
* **`np.random.seed(0)`**: 데이터 분할이나 모델 초기값 설정 시, 코드를 다시 실행해도 항상 똑같은 결과가 나오도록 랜덤성을 통제(시드 고정)합니다.
# 🔍 Fetal Health Classification: 탐색적 데이터 분석 (EDA)
## 1. 데이터 로드 및 기본 정보 확인 (Data Overview)
데이터의 전반적인 '건강 상태(결측치, 데이터 타입, 스케일)'를 진단합니다.
    * **`.T` (Transpose)**: 변수(컬럼)가 많을 때 표를 가로세로로 뒤집어서 읽기 편하게 만들어주는 분석가의 센스 있는 코드입니다!
    * **DA Insight**: 여기서 심박수(Baseline Value)와 자궁 수축(Uterine Contractions) 등 각 변수들의 '단위(Scale)'가 얼마나 다른지 파악하고, 추후 `StandardScaler`가 왜 필요한지 근거를 얻습니다.
## 2. 타겟 변수 불균형 확인 (Target Class Distribution)
머신러닝, 특히 의료 데이터 분석에서 **가장 중요한 시각화**입니다. 태아의 건강 상태(`fetal_health`)가 어떻게 분포되어 있는지 확인합니다.
* **Insight (클래스 불균형 - Class Imbalance)**: 
    * 의료 데이터 특성상 '정상(Normal)' 데이터가 압도적으로 많고, '병적(Pathologic)' 데이터는 극소수일 수밖에 없습니다. 
    * 이 그래프를 통해 데이터가 **불균형(Imbalanced)**하다는 것을 시각적으로 증명하고, 이후 모델 평가 시 '정확도(Accuracy)' 대신 '재현율(Recall)'과 'F1-Score'를 중요하게 봐야 한다는 전략을 세우게 됩니다.

## 3. 변수 간 상관관계 분석 (Correlation Matrix Heatmap)
어떤 특징(Feature)이 태아의 건강 상태와 가장 뚜렷한 연관이 있는지, 혹은 쓸데없이 겹치는 변수는 없는지 분석합니다.
* **Insight (다중공선성과 예측력)**: 
    * **타겟과의 상관관계**: `fetal_health` 행/열을 유심히 보며, 어떤 변수가 짙은 색(양/음의 강한 상관관계)을 띠는지 찾습니다. 이 변수들이 모델의 핵심 힌트가 됩니다.
    * **변수들 간의 상관관계 (다중공선성)**: 예를 들어 '히스토그램의 평균'과 '히스토그램의 중앙값'은 서로 매우 강한 상관관계를 가질 확률이 높습니다. 똑같은 의미를 지닌 변수들이 모델에 중복해서 들어가면 방해가 될 수 있으므로, 이를 걸러내는 잣대가 됩니다.

# 📈 Fetal Health Classification: 다변량 산점도 및 추세 분석 (lmplot)

히트맵을 통해 파악한 주요 변수들이 실제 데이터 포인트에서 어떤 군집을 이루고, 어떤 선형적 관계를 가지는지 `fetal_movement`(태아의 움직임)를 축으로 삼아 심층 분석하는 과정입니다.

## 1. 분석 코드의 핵심 기능 (`sns.lmplot`)
이 코드는 단순한 점 찍기(Scatter plot)를 넘어, 각 그룹별 데이터의 흐름을 보여주는 **회귀선(Regression Line)**을 함께 그려줍니다.

* **`sns.lmplot(...)`**: 산점도 위에 선형 회귀 추세선을 겹쳐 그리는 강력한 함수입니다. 변수 간의 비례/반비례 관계를 직관적으로 볼 수 있습니다.
* **`hue="fetal_health"`**: 이 분석의 핵심 키입니다! 데이터를 정상(1), 의심(2), 병적(3) 상태로 나누어 색깔별로 점과 추세선을 따로 그립니다. 
* **`legend_out=False`**: 범례를 그래프 밖으로 밀어내지 않고 안에 깔끔하게 배치하여 가독성을 높입니다.

## 2. 데이터 애널리스트(DA) 인사이트: 4가지 그래프 해석 가이드


[Image of scatter plot with regression lines by category]

결과물로 나오는 4개의 그래프를 보실 때, 단순히 점의 분포뿐만 아니라 **'색깔별 추세선의 기울기'**와 **'점들이 뭉쳐있는 위치'**가 클래스(건강 상태)마다 어떻게 다른지 비교하는 것이 중요합니다.

* **그래프 1: 가속도(Accelerations) vs 태아 움직임**
    * 정상적인 태아(Pink)는 움직임과 심박 가속도 사이에 특정 비례 관계가 나타날 수 있습니다. 반면, 병적 상태(Dark Blue)의 태아는 움직임이나 가속도 자체가 현저히 낮아 그래프의 왼쪽 아래 구석(0,0 주변)에 점들이 밀집해 있을 가능성이 높습니다.
* **그래프 2: 지속적 감속(Prolongued Decelerations) vs 태아 움직임**
    * 감속(심박수 저하)은 태아 건강에 치명적인 신호일 수 있습니다. 특정 색상(병적 상태)의 데이터가 감속 수치가 높은 오른쪽 영역에 주로 분포하는지 확인하여, 이 변수가 분류 모델의 강력한 무기(Feature)가 될 수 있음을 증명합니다.
* **그래프 3: 비정상적 단기 변동성(Abnormal Short Term Variability) vs 태아 움직임**
    * 변동성의 이상 수치가 높을수록 '정상' 클래스의 추세선과 '병적' 클래스의 추세선이 엇갈리거나 완전히 다른 기울기를 보일 수 있습니다. 이는 두 변수의 조합이 건강 상태를 가르는 훌륭한 기준선이 됨을 시사합니다.
* **그래프 4: 장기 변동성 평균(Mean Value of Long Term Variability) vs 태아 움직임**
    * 정상 상태와 비정상 상태의 태아가 장기 변동성 측면에서 뚜렷한 경계(Margin)를 가지고 나뉘는지 확인합니다. 점들이 색깔별로 잘 구분되어 있다면, 추후 사용할 결정 트리(Decision Tree)나 SVM 모델이 매우 쉽게 정답을 맞힐 수 있다는 뜻입니다.

**💡 요약:** 이 4개의 그래프에서 색깔(클래스)별로 점들이 확연히 따로 뭉쳐 있거나 추세선의 방향이 다르다면, 우리가 고른 이 변수들이 모델의 예측 성능을 확 끌어올려 줄 **'핵심 피처(Key Features)'**라는 것을 시각적으로 증명해 낸 것입니다.

# 📊 Fetal Health Classification: 세부 분포 분석 및 스케일 비교

각 건강 지표(변수)들이 태아의 상태(Target)에 따라 어떤 차이를 보이는지, 그리고 변수들 간의 단위(Scale) 차이가 얼마나 큰지 시각적으로 증명하는 단계입니다. 이 과정은 모델링 전 '이상치(Outlier)'와 '스케일링(Scaling)'의 필요성을 판단하는 핵심 근거가 됩니다.

## 1. 변수별 세부 분포 분석 (Swarmplot + Boxenplot)
중요한 11개의 컬럼(`cols`)을 하나씩 순회하며, 건강 상태(`fetal_health`) 3가지 클래스에 따른 분포 차이를 그립니다. 두 가지 그래프를 겹쳐 그려 정보량을 극대화했습니다.

* **`sns.swarmplot(...)`**: 개별 데이터 포인트를 하나하나 점(검은색, 반투명)으로 찍어서 보여줍니다. 데이터가 어디에 가장 많이 뭉쳐 있는지 **실제 밀집도**를 직관적으로 확인할 수 있습니다.
* **`sns.boxenplot(...)`**: 일반 박스플롯의 진화형으로, 데이터가 많을 때 꼬리(Tail) 부분의 분포와 **이상치(Outlier)**를 더 여러 단계의 상자로 세밀하게 보여줍니다. 
* **DA Insight (의료 데이터의 이상치)**: 
    * 의료 데이터에서는 평균보다 한참 벗어난 '이상치'가 곧 '질병(Pathologic)'의 신호일 때가 많습니다. 
    * 11개의 그래프를 확인하면서, 예를 들어 `prolongued_decelerations`(지속적 감속) 수치가 특정 클래스(병적 상태)에서만 비정상적으로 높게 뻗어 나가는 패턴이 있다면, 이는 모델이 정답을 맞히는 데 아주 중요한 핵심 변수가 됩니다.

## 2. 전체 변수 스케일 비교 (Overall Feature Scaling Check)
모든 변수를 하나의 거대한 도화지에 올려놓고 비교합니다.

* **`sns.boxenplot(data=data, palette=shades)`**: x축이나 y축을 따로 지정하지 않고 데이터프레임 전체를 넣으면, 각 컬럼들의 분포가 나란히 그려집니다.
* **`plt.xticks(rotation=90)`**: x축에 적힌 긴 변수 이름들이 겹치지 않도록 90도로 세워줍니다.
* **DA Insight (스케일링의 절대적 필요성 증명)**: 
    * 이 그래프를 출력하면 `baseline value`(기초 심박수) 같은 변수는 120~160 사이의 큰 숫자를 가지는 반면, `uterine_contractions`(자궁 수축) 같은 변수는 0에 가까운 아주 작은 소수점으로 바닥에 붙어 있는 것을 보게 됩니다.
    * 만약 이 상태 그대로 머신러닝(특히 SVM이나 KNN 같은 거리 기반 모델)을 돌리면, 컴퓨터는 숫자가 큰 '기초 심박수'만 중요하다고 착각해버립니다. 
    * 따라서 이 시각화는 다음 단계에서 **"우리가 왜 `StandardScaler`를 써서 모든 숫자의 체급을 공평하게 맞춰주어야 하는지"**를 보여주는 가장 강력한 논리적 근거가 됩니다.

# 🛠️ Fetal Health Classification: 데이터 전처리 및 스케일링

본격적으로 머신러닝 모델에게 데이터를 학습시키기 전, 데이터를 모델이 소화하기 가장 좋은 형태로 가공하는 필수 단계입니다.

## 1. 문제(X)와 정답(y) 분리
머신러닝의 지도 학습(Supervised Learning)을 위해 데이터를 입력값과 출력값으로 나눕니다.
* **`X = data.drop(["fetal_health"], axis=1)`**: 모델이 분석할 '문제지(Features)'입니다. 정답인 건강 상태 컬럼만 쏙 빼고 나머지 모든 의료 지표를 가져옵니다.
* **`y = data["fetal_health"]`**: 모델이 최종적으로 예측하고 맞춰야 할 '정답지(Target)'입니다.

## 2. 피처 스케일링 (Standard Scaling)
앞선 Boxenplot 시각화에서 변수들 간의 단위(체급) 차이가 엄청나게 큰 것을 확인했습니다. 이 체급을 똑같이 맞춰주는 핵심 작업입니다.

* **`preprocessing.StandardScaler()`**: 모든 변수들의 평균(Mean)을 0, 표준편차(Std)를 1로 변환해주는 스케일러입니다.
* **`fit_transform(X)`**: X 데이터의 평균과 표준편차를 계산(`fit`)하고, 그 수식을 바탕으로 데이터를 변환(`transform`)합니다.
* **DA Insight (스케일링의 위력)**: 
    * 변환 후 `X_df.describe().T`를 실행하면 모든 변수의 `mean`이 0에 수렴하고, `std`가 1로 완벽하게 통일된 것을 볼 수 있습니다. 
    * 이제 SVM, KNN, 로지스틱 회귀와 같은 거리/수식 기반 모델들이 숫자가 큰 특정 변수에만 치우치지 않고, 모든 변수를 공평하게 바라보며 학습할 수 있게 되었습니다!

## 3. 스케일링 결과 시각화 검증
* **`sns.boxenplot(data = X_df, ...)`**: 앞서 널뛰기하며 제각각이던 거대한 박슨플롯이 이제는 **0을 중심으로 가지런하고 동일한 범위 내에 정렬된 모습**을 띄게 됩니다. 데이터 분석가로서 "나의 전처리가 완벽하게 적용되었다"는 것을 시각적으로 증명하는 아주 멋진 코드입니다.

## 4. 학습용(Train)과 시험용(Test) 데이터 분리
수능을 치르기 전에 모의고사로 공부를 해야 하듯, 모델도 공부할 데이터와 나중에 실력을 평가받을 데이터를 엄격하게 나누어야 합니다.

* **`train_test_split(..., test_size=0.3, random_state=42)`**: 전체 데이터를 70% 대 30% 비율로 쪼갭니다. 
    * 70% (`X_train`, `y_train`): 모델을 훈련시키는 데 사용합니다.
    * 30% (`X_test`, `y_test`): 나중에 모델이 한 번도 본 적 없는 데이터를 얼마나 잘 맞추는지 채점하는 데 사용합니다.
* **`random_state=42`**: 코드를 다시 실행해도 데이터를 분할하는 기준이 바뀌지 않도록 난수표를 고정합니다. (42는 데이터 과학자들 사이에서 관행적으로 가장 많이 쓰는 숫자입니다!)

# 🤖 Fetal Health Classification: 모델 선택 및 교차 검증 (Model Selection & Cross Validation)

여러 알고리즘을 하나씩 따로 돌려보는 대신, 리스트와 반복문(Loop)을 활용해 4가지 주요 분류 모델을 한 번에 훈련시키고 공정하게 평가하는 효율적인 워크플로우입니다.

## 1. 파이프라인(Pipeline) 구축
머신러닝의 뼈대인 분류기(Classifier)들을 파이프라인이라는 캡슐 안에 담습니다.
* **`Pipeline(...)`**: 당장은 모델(분류기) 하나만 들어있지만, 추후 스케일러(Scaler)나 결측치 처리기 등을 이 파이프라인 안에 추가해 데이터가 물 흐르듯 한 번에 처리되도록 확장할 수 있는 아주 좋은 코딩 습관입니다.
* **4가지 모델 출전**: 로지스틱 회귀(`LogisticRegression`), 의사결정 나무(`DecisionTreeClassifier`), 랜덤 포레스트(`RandomForestClassifier`), 서포트 벡터 머신(`SVC`)이 경쟁 모델로 설정되었습니다.

## 2. 모델 일괄 학습 (Fit the Pipelines)
* **`pipe.fit(X_train, y_train)`**: 반복문(`for`)을 사용해 4개의 모델 파이프라인에 학습용 데이터(`X_train`, `y_train`)를 연속적으로 밀어 넣고 훈련시킵니다. 코드가 훨씬 간결해집니다.

## 3. 10-Fold 교차 검증 (Cross Validation)
단 한 번의 시험(Train/Test Split)으로 모델의 실력을 단정 짓지 않고, 데이터를 여러 조각으로 나누어 여러 번 시험을 치르게 하는 가장 확실한 검증 방법입니다. 여기서 모델의 진짜 실력이 드러나며, 이 코드가 전체 분석에서 가장 **가격값을 하는** 견고한 평가 방식입니다.



* **`cross_val_score(..., cv=10)`**: 학습 데이터(`X_train`)를 10개의 조각(Fold)으로 나눕니다. 9개 조각으로 공부하고 1개 조각으로 시험 보는 과정을 총 10번 반복합니다.
* **`cv_score.mean()`**: 10번 치른 시험 성적(정확도)의 평균을 내어, 모델이 우연히 점수가 잘 나온 것이 아님을 증명합니다.

## 4. 최종 테스트 셋 예측 (Test Set Prediction)
교차 검증 결과, 보통 가장 성능이 우수하게 나오는 앙상블 모델인 **랜덤 포레스트(RandomForest)**를 최종 대표 모델로 선정하여 실전 테스트를 진행합니다.
* **`pred_rfc = pipeline_rf.predict(X_test)`**: 모델이 태어나서 한 번도 본 적 없는 실전 데이터(`X_test`)의 정답을 예측해 봅니다.
* **`accuracy_score(y_test, pred_rfc)`**: 모델의 예측값과 실제 정답(`y_test`)을 비교하여 최종 실전 정확도(Accuracy)를 계산합니다.

## 💡 데이터 애널리스트(DA) 인사이트
이 코드를 통해 우수한 정확도(Accuracy)를 얻었더라도 기뻐하기엔 아직 이릅니다! 앞선 EDA 단계에서 **클래스 불균형(정상 태아가 압도적으로 많음)**을 확인했기 때문입니다. 
따라서 이 정확도 수치에 속지 않고, 다음 단계에서 **혼동 행렬(Confusion Matrix)**이나 **분류 보고서(Classification Report)**를 통해 '병적(Pathologic)' 상태를 얼마나 잘 잡아냈는지(재현율, Recall) 반드시 확인해야 합니다.

# ⚙️ Fetal Health Classification: 하이퍼파라미터 튜닝 (GridSearchCV)

앞서 선택된 '랜덤 포레스트(Random Forest)' 모델의 성능을 극한까지 끌어올리기 위해, 모델의 세부 설정값(Hyperparameter)을 자동으로 탐색하고 최적화하는 과정입니다.

## 1. 탐색 공간(Parameter Grid) 설정
모델에게 "이 옵션들 중에서 가장 좋은 조합을 찾아봐!"라고 지시할 메뉴판(Dictionary)을 만듭니다.
* **`n_estimators`**: 숲을 구성할 나무(Decision Tree)의 개수입니다. 많을수록 성능이 안정되지만 학습이 오래 걸립니다. (100개부터 900개까지 테스트)
* **`max_features`**: 각 나무가 가지를 칠 때 고려할 변수의 개수 제한 방식입니다.
* **`max_depth`**: 나무가 얼마나 깊게 파고들지(질문의 깊이)를 정합니다. 너무 깊으면 과적합(Overfitting)이 발생하므로 적절한 깊이를 찾는 것이 핵심입니다.
* **`criterion`**: 데이터를 분할할 때 불순도를 측정하는 기준('gini' 계수 또는 'entropy')입니다.
* **`n_jobs`**: 컴퓨터의 CPU 코어를 얼마나 쓸지 결정합니다. `-1`은 "모든 코어를 다 써서 제일 빠르게 계산해!"라는 뜻입니다.

## 2. GridSearchCV: 자동화된 최적 조합 탐색
우리가 설정한 모든 파라미터 조합의 경우의 수를 다 돌려보는 '완전 탐색(Brute-force)' 알고리즘입니다.



* **`GridSearchCV(..., cv=5)`**: 설정한 수백 가지의 옵션 조합을 각각 **5-Fold 교차 검증**으로 테스트합니다. 시간은 꽤 걸리지만, 모델이 우연히 훈련 데이터에만 맞춰지는(Overfitting) 현상을 완벽하게 방지할 수 있습니다.
* **`CV_rfc.fit(X_train, y_train)`**: 모델이 훈련 데이터 안에서 스스로 수백 번의 모의고사를 치르며 가장 점수가 높은 파라미터 조합을 찾아냅니다.

## 3. 최적의 모델 추출 및 최종 평가
* **`CV_rfc.best_params_`**: 수많은 테스트 끝에 찾아낸 1등 설정값들을 출력합니다.
* **`RandomForestClassifier(**CV_rfc.best_params_)`**: 파이썬의 별표 두 개(`**`) 언패킹 문법을 사용해, 딕셔너리 형태로 나온 1등 설정값들을 새로운 모델에 한 번에 쏙 집어넣는 아주 세련된 코드입니다.
* **`RF_model.fit(...)` & `predict(...)`**: 최종 완성된 '완전체' 랜덤 포레스트 모델을 다시 학습시키고, 한 번도 본 적 없는 실전 데이터(`X_test`)를 예측하게 하여 최종 정확도(`accuracy`)를 계산합니다.

## 💡 데이터 애널리스트(DA) 인사이트
이 과정을 거치고 나면 모델의 정확도가 소폭, 혹은 대폭 상승하는 것을 볼 수 있습니다. 하지만 이 프로젝트의 핵심은 '불균형한 의료 데이터'를 다루는 것입니다. 
아무리 최적화된 랜덤 포레스트가 95%의 높은 정확도를 냈더라도, 그것이 '건강한 태아를 100% 맞추고, 병에 걸린 태아를 절반이나 놓친 결과'라면 의료 현장에서는 쓸 수 없는 모델이 됩니다. 
따라서 이 **최종 모델이 각 클래스별로 얼마나 정답을 잘 맞췄는지 뜯어보는 상세 평가 지표 분석이 반드시 동반되어야 합니다.**
